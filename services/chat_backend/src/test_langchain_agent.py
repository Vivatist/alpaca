#!/usr/bin/env python3
"""
–¢–µ—Å—Ç–æ–≤—ã–π —Å–∫—Ä–∏–ø—Ç –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ LangChain Agent RAG.

–ó–∞–ø—É—Å–∫:
1. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏: pip install -r requirements-langchain.txt
2. –ó–∞–ø—É—Å—Ç–∏—Ç—å: python test_langchain_agent.py

–î–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –≤–Ω—É—Ç—Ä–∏ Docker:
docker exec -it alpaca-chat-backend-1 pip install langchain-ollama langgraph langchain-core
docker exec -it alpaca-chat-backend-1 python /app/src/test_langchain_agent.py
"""

import sys
import os

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ src
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

# –ú–æ–∫–∞–µ–º settings –¥–ª—è –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ –∑–∞–ø—É—Å–∫–∞
class MockSettings:
    OLLAMA_BASE_URL = os.getenv("OLLAMA_BASE_URL", "http://localhost:11434")
    OLLAMA_LLM_MODEL = os.getenv("OLLAMA_LLM_MODEL", "qwen2.5:32b")
    LLM_BACKEND = "langchain_agent"

# –ü–∞—Ç—á–∏–º settings
import settings as settings_module
settings_module.settings = MockSettings()


def mock_search(query: str):
    """–ú–æ–∫ —Ñ—É–Ω–∫—Ü–∏–∏ –ø–æ–∏—Å–∫–∞ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è."""
    print(f"üîç Mock search called with: {query}")
    return [
        {
            "content": "ALPACA ‚Äî —ç—Ç–æ RAG —Å–∏—Å—Ç–µ–º–∞ –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –¥–æ–∫—É–º–µ–Ω—Ç–∞–º–∏ –∫–æ–º–ø–∞–Ω–∏–∏. "
                      "–û–Ω–∞ –ø–æ–∑–≤–æ–ª—è–µ—Ç –∏—Å–∫–∞—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –≤ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ö –∏ –æ—Ç–≤–µ—á–∞—Ç—å –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã.",
            "metadata": {
                "file_path": "docs/README.md",
                "title": "ALPACA RAG System",
                "chunk_index": 0,
            },
            "similarity": 0.95,
        },
        {
            "content": "–°–∏—Å—Ç–µ–º–∞ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç Ollama –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –∏ –æ—Ç–≤–µ—Ç–æ–≤. "
                      "–î–æ–∫—É–º–µ–Ω—Ç—ã —Ö—Ä–∞–Ω—è—Ç—Å—è –≤ PostgreSQL —Å —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ–º pgvector.",
            "metadata": {
                "file_path": "docs/architecture.md", 
                "title": "Architecture",
                "chunk_index": 1,
            },
            "similarity": 0.85,
        },
    ]


def test_sync():
    """–¢–µ—Å—Ç —Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–π –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏."""
    print("\n" + "="*60)
    print("TEST: –°–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è")
    print("="*60)
    
    from llm.langchain_agent import generate_response, set_search_function
    
    set_search_function(mock_search)
    
    response = generate_response(
        prompt="–ß—Ç–æ —Ç–∞–∫–æ–µ ALPACA?",
        system_prompt="–¢—ã –ø–æ–ª–µ–∑–Ω—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç. –ò—Å–ø–æ–ª—å–∑—É–π –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç –ø–æ–∏—Å–∫–∞ –¥–ª—è –æ—Ç–≤–µ—Ç–∞ –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã.",
    )
    
    print(f"\n–û—Ç–≤–µ—Ç:\n{response}")


def test_stream():
    """–¢–µ—Å—Ç –ø–æ—Ç–æ–∫–æ–≤–æ–π –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏."""
    print("\n" + "="*60)
    print("TEST: –ü–æ—Ç–æ–∫–æ–≤–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è")
    print("="*60)
    
    from llm.langchain_agent import generate_response_stream, set_search_function
    
    set_search_function(mock_search)
    
    print("\n–û—Ç–≤–µ—Ç (streaming):")
    for chunk in generate_response_stream(
        prompt="–†–∞—Å—Å–∫–∞–∂–∏ –ø—Ä–æ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É —Å–∏—Å—Ç–µ–º—ã ALPACA",
        system_prompt="–¢—ã –ø–æ–ª–µ–∑–Ω—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç. –ò—Å–ø–æ–ª—å–∑—É–π –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç –ø–æ–∏—Å–∫–∞ –¥–ª—è –æ—Ç–≤–µ—Ç–∞ –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã.",
    ):
        print(chunk, end="", flush=True)
    print("\n")


def test_without_tools():
    """–¢–µ—Å—Ç –±–µ–∑ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤."""
    print("\n" + "="*60)
    print("TEST: –ü—Ä–æ—Å—Ç–æ–π –≤–æ–ø—Ä–æ—Å (–±–µ–∑ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤)")
    print("="*60)
    
    from llm.langchain_agent import generate_response_stream
    
    print("\n–û—Ç–≤–µ—Ç (streaming):")
    for chunk in generate_response_stream(
        prompt="–°–∫–æ–ª—å–∫–æ –±—É–¥–µ—Ç 2+2?",
        system_prompt="–û—Ç–≤–µ—á–∞–π –∫—Ä–∞—Ç–∫–æ.",
    ):
        print(chunk, end="", flush=True)
    print("\n")


if __name__ == "__main__":
    print("üß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ LangChain Agent RAG")
    print(f"üì° Ollama URL: {MockSettings.OLLAMA_BASE_URL}")
    print(f"ü§ñ Model: {MockSettings.OLLAMA_LLM_MODEL}")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å LangChain
    try:
        from langchain_ollama import ChatOllama
        from langgraph.prebuilt import create_react_agent
        print("‚úÖ LangChain dependencies available")
    except ImportError as e:
        print(f"‚ùå LangChain not installed: {e}")
        print("\n–£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏:")
        print("pip install langchain-ollama langgraph langchain-core")
        sys.exit(1)
    
    # –ó–∞–ø—É—Å–∫–∞–µ–º —Ç–µ—Å—Ç—ã
    try:
        test_without_tools()
        test_sync()
        test_stream()
        print("\n‚úÖ –í—Å–µ —Ç–µ—Å—Ç—ã –∑–∞–≤–µ—Ä—à–µ–Ω—ã!")
    except Exception as e:
        print(f"\n‚ùå –û—à–∏–±–∫–∞: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)

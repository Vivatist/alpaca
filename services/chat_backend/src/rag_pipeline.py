"""
RAG Service - –æ—Ä–∫–µ—Å—Ç—Ä–∞—Ç–æ—Ä pipeline.

–û–±—ä–µ–¥–∏–Ω—è–µ—Ç searcher –∏ LLM –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–æ–≤.
"""

from typing import List, Dict, Any, Optional
import uuid

from logging_config import get_logger
from settings import settings
from repository import ChatRepository
from embedders import build_embedder
from vector_searchers import build_searcher
from llm import generate_response

logger = get_logger("chat_backend.rag")


# –°–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç –¥–ª—è RAG
RAG_SYSTEM_PROMPT = """–¢—ã ‚Äî –ø–æ–ª–µ–∑–Ω—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –∫–æ–º–ø–∞–Ω–∏–∏ ALPACA. –û—Ç–≤–µ—á–∞–π –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è, –∏—Å–ø–æ–ª—å–∑—É—è –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤.

–ü—Ä–∞–≤–∏–ª–∞:
1. –û—Ç–≤–µ—á–∞–π –¢–û–õ–¨–ö–û –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
2. –ï—Å–ª–∏ –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ –Ω–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –¥–ª—è –æ—Ç–≤–µ—Ç–∞ ‚Äî —á–µ—Å—Ç–Ω–æ —Å–∫–∞–∂–∏ –æ–± —ç—Ç–æ–º
3. –ù–ï –ø–µ—Ä–µ—á–∏—Å–ª—è–π –∏—Å—Ç–æ—á–Ω–∏–∫–∏ –≤ —Ç–µ–∫—Å—Ç–µ –æ—Ç–≤–µ—Ç–∞ ‚Äî –æ–Ω–∏ –±—É–¥—É—Ç –¥–æ–±–∞–≤–ª–µ–Ω—ã –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ—Ç–¥–µ–ª—å–Ω–æ
4. –û—Ç–≤–µ—á–∞–π –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ
5. –ë—É–¥—å —Ç–æ—á–Ω—ã–º –∏ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–º"""


class RAGService:
    """–°–µ—Ä–≤–∏—Å RAG –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤."""
    
    def __init__(self, repository: ChatRepository):
        self.repository = repository
        embedder = build_embedder()
        self.searcher = build_searcher(embedder, repository)
    
    def build_prompt(self, query: str, chunks: List[Dict[str, Any]]) -> str:
        """
        –§–æ—Ä–º–∏—Ä—É–µ—Ç prompt –¥–ª—è LLM —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º.
        
        Args:
            query: –í–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            chunks: –†–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ —á–∞–Ω–∫–∏
            
        Returns:
            –ì–æ—Ç–æ–≤—ã–π prompt –¥–ª—è LLM
        """
        if not chunks:
            context = "–ö–æ–Ω—Ç–µ–∫—Å—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω. –û—Ç–≤–µ—á–∞–π –Ω–∞ –æ—Å–Ω–æ–≤–µ –æ–±—â–∏—Ö –∑–Ω–∞–Ω–∏–π, –Ω–æ —É–∫–∞–∂–∏, —á—Ç–æ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –Ω–µ –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –∫–æ–º–ø–∞–Ω–∏–∏."
        else:
            context_parts = []
            for i, chunk in enumerate(chunks, 1):
                source = chunk.get("metadata", {}).get("file_path", "–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π –∏—Å—Ç–æ—á–Ω–∏–∫")
                similarity = chunk.get("similarity", 0)
                content = chunk.get("content", "")
                context_parts.append(
                    f"[–ò—Å—Ç–æ—á–Ω–∏–∫ {i}: {source} (—Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å: {similarity:.2f})]\n{content}"
                )
            context = "\n\n".join(context_parts)
        
        prompt = f"""–ö–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤:
{context}

–í–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è: {query}

–û—Ç–≤–µ—Ç:"""
        
        return prompt
    
    def generate_answer(
        self,
        query: str,
        conversation_id: Optional[str] = None
    ) -> Dict[str, Any]:
        """
        –ü–æ–ª–Ω—ã–π RAG pipeline: –ø–æ–∏—Å–∫ ‚Üí –ø—Ä–æ–º–ø—Ç ‚Üí –≥–µ–Ω–µ—Ä–∞—Ü–∏—è.
        
        Args:
            query: –í–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            conversation_id: ID —Ä–∞–∑–≥–æ–≤–æ—Ä–∞ (–¥–ª—è –∏—Å—Ç–æ—Ä–∏–∏)
            
        Returns:
            Dict —Å answer, conversation_id, sources
        """
        logger.info(f"üîç RAG query: {query[:50]}...")
        
        # 1. –ü–æ–∏—Å–∫ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
        chunks = self.searcher.search(query)
        
        # 2. –§–æ—Ä–º–∏—Ä—É–µ–º –ø—Ä–æ–º–ø—Ç
        prompt = self.build_prompt(query, chunks)
        
        # 3. –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç
        answer = generate_response(
            prompt=prompt,
            system_prompt=RAG_SYSTEM_PROMPT
        )
        
        if not answer:
            answer = "–ò–∑–≤–∏–Ω–∏—Ç–µ, –Ω–µ —É–¥–∞–ª–æ—Å—å —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –æ—Ç–≤–µ—Ç. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ."
        
        # 4. –§–æ—Ä–º–∏—Ä—É–µ–º –∏—Å—Ç–æ—á–Ω–∏–∫–∏
        sources = []
        for chunk in chunks:
            metadata = chunk.get("metadata", {})
            sources.append({
                "file_path": metadata.get("file_path", ""),
                "chunk_index": metadata.get("chunk_index", 0),
                "similarity": chunk.get("similarity", 0),
            })
        
        # 5. –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º conversation_id –µ—Å–ª–∏ –Ω–µ –ø–µ—Ä–µ–¥–∞–Ω
        if not conversation_id:
            conversation_id = str(uuid.uuid4())
        
        logger.info(f"‚úÖ RAG response generated | sources={len(sources)}")
        
        return {
            "answer": answer,
            "conversation_id": conversation_id,
            "sources": sources,
        }


# Singleton instance (–∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç—Å—è –ø—Ä–∏ –ø–µ—Ä–≤–æ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–∏)
_rag_service: Optional[RAGService] = None


def get_rag_service() -> RAGService:
    """–ü–æ–ª—É—á–∏—Ç—å singleton RAG —Å–µ—Ä–≤–∏—Å–∞."""
    global _rag_service
    if _rag_service is None:
        repository = ChatRepository(settings.DATABASE_URL)
        _rag_service = RAGService(repository)
    return _rag_service


__all__ = [
    "RAGService",
    "get_rag_service",
]

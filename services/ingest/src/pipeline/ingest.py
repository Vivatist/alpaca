"""
IngestDocument - –ø–æ–ª–Ω—ã–π –ø–∞–π–ø–ª–∞–π–Ω –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞.

–®–∞–≥–∏:
1. Parse - –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–∞
2. Clean - –æ—á–∏—Å—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞ (optional)
3. MetaExtract - –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö (optional)
4. Chunk - —Ä–∞–∑–±–∏–µ–Ω–∏–µ –Ω–∞ —á–∞—Å—Ç–∏
5. Embed - —Å–æ–∑–¥–∞–Ω–∏–µ –≤–µ–∫—Ç–æ—Ä–æ–≤ –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ –ë–î
"""

from __future__ import annotations
import os
from dataclasses import dataclass, field
from threading import Semaphore
from typing import Optional, Callable, Dict, Any, List

from logging_config import get_logger
from contracts import (
    FileSnapshot, 
    Repository, 
    ParserRegistry, 
    Chunker, 
    Embedder, 
    MetaExtractor
)
from settings import settings


@dataclass
class IngestDocument:
    """–ü–æ–ª–Ω—ã–π –ø–∞–π–ø–ª–∞–π–Ω –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞."""
    
    # –û–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã
    repository: Repository
    parser_registry: ParserRegistry
    chunker: Chunker
    embedder: Embedder
    parse_semaphore: Semaphore
    embed_semaphore: Semaphore
    
    # –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã
    cleaner: Optional[Callable[[str], str]] = None
    metaextractor: Optional[MetaExtractor] = None
    temp_dir: str = field(default_factory=lambda: settings.TMP_MD_PATH)
    logger_name: str = field(default="ingest.pipeline")
    
    def __post_init__(self):
        self.logger = get_logger(self.logger_name)
    
    def __call__(self, file: FileSnapshot) -> bool:
        """
        –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–∞–π–ª–∞ —á–µ—Ä–µ–∑ –≤–µ—Å—å –ø–∞–π–ø–ª–∞–π–Ω.
        
        Args:
            file: FileSnapshot —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ —Ñ–∞–π–ª–µ
            
        Returns:
            True –µ—Å–ª–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∞ —É—Å–ø–µ—à–Ω–∞
        """
        self.logger.info(f"üçé Start ingest pipeline | file={file.path} hash={file.hash[:8]}...")
        
        try:
            # 1. Parse
            parser = self.parser_registry.get_parser(file.path)
            if parser is None:
                self.logger.error(f"Unsupported file type | file={file.path}")
                self.repository.mark_as_error(file.hash)
                return False
            
            with self.parse_semaphore:
                file.raw_text = parser.parse(file)
                self.repository.set_raw_text(file.hash, file.raw_text)
            
            self.logger.info(f"‚úÖ Parsed | chars={len(file.raw_text) if file.raw_text else 0}")
            
            # 1.1. Save to disk for debugging
            self._save_to_disk(file)
            
            # 2. Clean (–µ—Å–ª–∏ cleaner –∑–∞–¥–∞–Ω)
            if self.cleaner is not None:
                file.raw_text = self.cleaner(file.raw_text)
                self.logger.info(f"‚úÖ Cleaned | chars={len(file.raw_text) if file.raw_text else 0}")
            
            # 3. Extract metadata (–µ—Å–ª–∏ metaextractor –∑–∞–¥–∞–Ω)
            if self.metaextractor is not None:
                file.metadata = self.metaextractor(file)
                self.logger.info(f"‚úÖ Metadata | keys={list(file.metadata.keys()) if file.metadata else []}")
            else:
                file.metadata = {}
            
            # 4. Chunk
            chunks = self.chunker(file)
            if not chunks:
                self.logger.warning(f"No chunks created | file={file.path}")
                self.repository.mark_as_error(file.hash)
                return False
            
            self.logger.info(f"‚úÖ Chunked | count={len(chunks)}")
            
            # 5. Embed
            with self.embed_semaphore:
                chunks_count = self.embedder(self.repository, file, chunks, file.metadata)
            
            if chunks_count == 0:
                self.logger.warning(f"No embeddings created | file={file.path}")
                self.repository.mark_as_error(file.hash)
                return False
            
            # 6. Mark success
            self.repository.mark_as_ok(file.hash)
            self.logger.info(f"‚úÖ File processed successfully | file={file.path} chunks={chunks_count}")
            return True
            
        except Exception as exc:
            import traceback
            self.logger.error(f"Pipeline failed | file={file.path} error={exc}")
            self.logger.error(f"Traceback:\n{traceback.format_exc()}")
            self.repository.mark_as_error(file.hash)
            return False
    
    def _save_to_disk(self, file: FileSnapshot) -> None:
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–∞—Å–ø–∞—Ä—Å–µ–Ω–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞ –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏."""
        if not file.raw_text:
            return
        
        try:
            temp_file_path = os.path.join(self.temp_dir, f"{file.path}.md")
            os.makedirs(os.path.dirname(temp_file_path), exist_ok=True)
            with open(temp_file_path, "w", encoding="utf-8") as f:
                f.write(file.raw_text)
            self.logger.debug(f"üíæ Saved to {temp_file_path}")
        except Exception as e:
            self.logger.warning(f"Failed to save debug file | error={e}")

"""
Ingest Service - —Ç–æ—á–∫–∞ –≤—Ö–æ–¥–∞.

–ò–∑–æ–ª–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Å–µ—Ä–≤–∏—Å –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤:
- –ü–∞—Ä—Å–∏–Ω–≥ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —Ñ–æ—Ä–º–∞—Ç–æ–≤ (Word, PDF, Excel, PowerPoint, TXT)
- –û—á–∏—Å—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞ (pipeline –∫–ª–∏–Ω–µ—Ä–æ–≤)
- –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö (simple/llm)
- –ß–∞–Ω–∫–∏–Ω–≥ (simple/smart —Å overlap)
- –≠–º–±–µ–¥–¥–∏–Ω–≥ —á–µ—Ä–µ–∑ Ollama –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ pgvector
"""

from threading import Semaphore

from settings import settings
from logging_config import setup_logging, get_logger
from repository import IngestRepository
from worker import Worker

# –ö–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –ø–∞–π–ø–ª–∞–π–Ω–∞
from parsers import build_parser_registry
from cleaners import build_cleaner
from chunkers import build_chunker
from embedders import build_embedder
from metaextractors import build_metaextractor
from pipeline import IngestDocument, ProcessFileEvent


def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è —Å–µ—Ä–≤–∏—Å–∞."""
    
    # 1. –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
    setup_logging(settings.LOG_LEVEL)
    logger = get_logger("ingest.main")
    
    logger.info("=" * 60)
    logger.info("üöÄ Starting Ingest Service")
    logger.info("=" * 60)
    
    # 2. –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è
    logger.info("Initializing repository...")
    repository = IngestRepository(
        database_url=settings.DATABASE_URL,
        files_table="files",
        chunks_table="chunks"
    )
    
    # –°–±—Ä–æ—Å –∑–∞–≤–∏—Å—à–∏—Ö processed —Å—Ç–∞—Ç—É—Å–æ–≤
    reset_count = repository.reset_processed_to_added()
    if reset_count > 0:
        logger.info(f"üîÑ Reset {reset_count} stuck 'processed' files to 'added'")
    
    # 3. –°–±–æ—Ä–∫–∞ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤ –ø–∞–π–ø–ª–∞–π–Ω–∞
    logger.info("Building pipeline components...")
    
    parser_registry = build_parser_registry()
    logger.info(f"Parsers: {parser_registry.supported_extensions()}")
    
    cleaner = build_cleaner()
    chunker = build_chunker()
    embedder = build_embedder()
    metaextractor = build_metaextractor()
    
    # –°–µ–º–∞—Ñ–æ—Ä—ã –¥–ª—è –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è –ø–∞—Ä–∞–ª–ª–µ–ª–∏–∑–º–∞
    parse_semaphore = Semaphore(settings.WORKER_MAX_CONCURRENT_PARSING)
    embed_semaphore = Semaphore(settings.WORKER_MAX_CONCURRENT_EMBEDDING)
    llm_semaphore = Semaphore(settings.WORKER_MAX_CONCURRENT_LLM)
    
    # 4. –°–±–æ—Ä–∫–∞ –ø–∞–π–ø–ª–∞–π–Ω–∞
    logger.info("Assembling pipeline...")
    
    ingest_document = IngestDocument(
        repository=repository,
        parser_registry=parser_registry,
        chunker=chunker,
        embedder=embedder,
        parse_semaphore=parse_semaphore,
        embed_semaphore=embed_semaphore,
        llm_semaphore=llm_semaphore,
        cleaner=cleaner,
        metaextractor=metaextractor,
        temp_dir=settings.TMP_MD_PATH,
    )
    
    process_file_event = ProcessFileEvent(
        ingest_document=ingest_document,
        repository=repository,
    )
    
    # 5. –°–æ–∑–¥–∞–Ω–∏–µ –∏ –∑–∞–ø—É—Å–∫ worker
    logger.info("Creating worker...")
    
    worker = Worker(
        repository=repository,
        filewatcher_api_url=settings.FILEWATCHER_URL,
        process_file_func=process_file_event,
    )
    
    logger.info("=" * 60)
    logger.info("‚úÖ Ingest Service ready")
    logger.info(f"  FileWatcher: {settings.FILEWATCHER_URL}")
    logger.info(f"  Ollama: {settings.OLLAMA_BASE_URL}")
    logger.info(f"  Cleaner pipeline: {settings.CLEANER_PIPELINE}")
    logger.info(f"  Chunker: {settings.CHUNKER_BACKEND} (size={settings.CHUNK_SIZE}, overlap={settings.CHUNK_OVERLAP})")
    logger.info(f"  MetaExtractor pipeline: {settings.METAEXTRACTOR_PIPELINE}")
    logger.info("=" * 60)
    
    # 6. –ó–∞–ø—É—Å–∫ worker
    worker.start(
        poll_interval=settings.WORKER_POLL_INTERVAL,
        max_workers=settings.WORKER_MAX_CONCURRENT_FILES,
    )


if __name__ == "__main__":
    main()

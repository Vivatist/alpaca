# =============================================================================
# ALPACA Services - Environment Configuration
# =============================================================================
# Скопируйте этот файл в .env и настройте под своё окружение:
#   cp .env.example .env
#
# Docker Compose автоматически загружает .env файл из текущей директории
# =============================================================================

# -----------------------------------------------------------------------------
# Ollama Configuration
# -----------------------------------------------------------------------------
# URL для подключения к Ollama API
# 
# Варианты:
#   - Локальный Ollama на хосте: http://host.docker.internal:11434
#   - Ollama в том же docker-compose: http://ollama:11434
#   - Удалённый сервер: http://server-ip:11434 или http://gpu-server.local:11434
#
OLLAMA_BASE_URL=http://host.docker.internal:11434

# Модели Ollama
# OLLAMA_EMBEDDING_MODEL=bge-m3
# OLLAMA_CHAT_MODEL=qwen2.5:32b

# -----------------------------------------------------------------------------
# Database Configuration (Supabase)
# -----------------------------------------------------------------------------
# По умолчанию используется локальный Supabase на порту 54322
# DATABASE_URL=postgresql://postgres:postgres@host.docker.internal:54322/postgres

# -----------------------------------------------------------------------------
# Chat Backend Configuration
# -----------------------------------------------------------------------------
# Тип бэкенда: simple | agent
# CHAT_BACKEND=simple

# RAG параметры
# RAG_TOP_K=5
# RAG_SIMILARITY_THRESHOLD=0.3

# -----------------------------------------------------------------------------
# Ingest Service Configuration
# -----------------------------------------------------------------------------
# Cleaner pipeline (последовательная обработка)
# CLEANER_PIPELINE=["simple","stamps"]

# Chunker backend: simple | smart
# CHUNKER_BACKEND=smart
# CHUNK_SIZE=1000
# CHUNK_OVERLAP=200

# MetaExtractor pipeline (последовательная обработка)
# METAEXTRACTOR_PIPELINE=["base","llm"]

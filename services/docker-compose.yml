name: alpaca

# ============================================================
# ALPACA Services (локальные)
# Ollama должен быть запущен отдельно (см. docker-compose.ollama.yml)
# 
# Настройка OLLAMA_BASE_URL:
#   - Локальный Ollama: export OLLAMA_BASE_URL=http://host.docker.internal:11434
#   - Удалённый сервер: export OLLAMA_BASE_URL=http://server-ip:11434
#   - Или создайте .env файл с этой переменной
# ============================================================

services:
  # Unstructured API для парсинга документов
  unstructured:
    image: downloads.unstructured.io/unstructured-io/unstructured-api:latest
    restart: always
    ports:
      - "9000:8000"
    environment:
      - UNSTRUCTURED_ALLOWED_MIMETYPES=application/pdf,application/vnd.openxmlformats-officedocument.wordprocessingml.document,application/vnd.openxmlformats-officedocument.spreadsheetml.sheet,application/vnd.openxmlformats-officedocument.presentationml.presentation,text/plain
      - UNSTRUCTURED_MEMORY_FREE_MINIMUM_MB=512
      - TZ=Europe/Moscow
      - LANG=C.UTF-8
      - LC_ALL=C.UTF-8
      - PYTHONIOENCODING=utf-8
      - UNSTRUCTURED_LANGUAGE=rus,eng
      - UNSTRUCTURED_OCR_LANGUAGES=rus
      - UNSTRUCTURED_USE_OCR_ALWAYS=auto
      - UNSTRUCTURED_PARALLEL_MODE=true
      - UNSTRUCTURED_PARALLEL_NUM_WORKERS=2
    volumes:
      - unstructured_data:/app/data
    healthcheck:
      test: ["CMD", "wget", "-q", "-O", "-", "http://127.0.0.1:8000/healthcheck"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    networks:
      - alpaca_network

  # ============================================================
  # ПРИМЕЧАНИЕ: Ollama вынесен в docker-compose.ollama.yml
  # Для локальной разработки с GPU на этой машине:
  #   docker compose -f docker-compose.yml -f docker-compose.ollama.yml up -d
  # Для работы с удалённым Ollama:
  #   OLLAMA_BASE_URL=http://server-ip:11434 docker compose up -d
  # ============================================================

  # File Watcher для мониторинга файлов
  filewatcher:
    build:
      context: ..
      dockerfile: services/file_watcher/Dockerfile
    restart: always
    networks:
      - alpaca_network
    ports:
      - "8081:8081"
    volumes:
      - ${MONITORED_FOLDER_PATH:-../monitored_folder}:/monitored_folder:ro
    environment:
      # === CREDENTIALS ===
      - DATABASE_URL=${DATABASE_URL}
      
      # === SYSTEM SETTINGS ===
      - TZ=Europe/Moscow
      - LOG_LEVEL=INFO
      
      # === FILE WATCHER SETTINGS (настройки только здесь) ===
      - FILES_TABLE_NAME=files
      - MONITORED_PATH=/monitored_folder
      - SCAN_INTERVAL_SECONDS=10
      - ALLOWED_EXTENSIONS=.docx,.doc,.pdf,.txt,.pptx,.ppt,.xlsx,.xls
      - FILE_MIN_SIZE=100
      - FILE_MAX_SIZE=10485760
      - EXCLUDED_DIRS=TMP
      - EXCLUDED_PATTERNS=~*,.*
      - PRE_LAUNCH_TESTS=true  # Тесты при запуске
    healthcheck:
      test: ["CMD", "python", "-c", "import urllib.request; urllib.request.urlopen('http://localhost:8081/health', timeout=5)"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s

  # Admin Backend для мониторинга и управления
  admin-backend:
    build:
      context: ..
      dockerfile: services/admin_backend/Dockerfile
    image: alpaca-admin-backend:latest
    restart: always
    networks:
      - alpaca_network
    ports:
      - "8080:8080"
    environment:
      - DATABASE_URL=${DATABASE_URL}
      - OLLAMA_BASE_URL=${OLLAMA_BASE_URL:-http://host.docker.internal:11434}
      - TZ=Europe/Moscow
    healthcheck:
      test: ["CMD", "python", "-c", "import urllib.request; urllib.request.urlopen('http://localhost:8080/health', timeout=5)"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s

  # Ingest Service - обработка документов
  ingest:
    build:
      context: ..
      dockerfile: services/ingest/Dockerfile
    image: alpaca-ingest:latest
    restart: always
    networks:
      - alpaca_network
    volumes:
      - ${MONITORED_FOLDER_PATH:-../monitored_folder}:/monitored_folder:ro
      - ${TMP_MD_PATH:-../tmp_md}:/tmp_md
    environment:
      # === CREDENTIALS ===
      - DATABASE_URL=${DATABASE_URL}
      
      # === SYSTEM SETTINGS ===
      - TZ=Europe/Moscow
      - LOG_LEVEL=INFO
      
      # === SERVICE URLs ===
      - FILEWATCHER_URL=http://filewatcher:8081
      - OLLAMA_BASE_URL=${OLLAMA_BASE_URL:-http://host.docker.internal:11434}
      - UNSTRUCTURED_API_URL=http://unstructured:8000/general/v0/general
      
      # === MODEL SETTINGS ===
      - OLLAMA_EMBEDDING_MODEL=bge-m3
      - OLLAMA_LLM_MODEL=qwen2.5:32b
      
      # === WORKER SETTINGS ===
      - WORKER_POLL_INTERVAL=5
      - WORKER_MAX_CONCURRENT_FILES=5
      - WORKER_MAX_CONCURRENT_PARSING=2
      - WORKER_MAX_CONCURRENT_EMBEDDING=3
      
      # === PIPELINE SETTINGS ===
      - ENABLE_CLEANER=true
      - CLEANER_PIPELINE=["simple","stamps"]
      - CHUNKER_BACKEND=smart # options: simple, smart
      - CHUNK_SIZE=1000
      - CHUNK_OVERLAP=200
      - ENABLE_METAEXTRACTOR=true
      - METAEXTRACTOR_PIPELINE=["base","llm"]
      - LLM_METAEXTRACTOR_PREVIEW_LENGTH=2000
      
      # === PATHS ===
      - MONITORED_PATH=/monitored_folder
      - TMP_MD_PATH=/tmp_md
    depends_on:
      - filewatcher
      - unstructured
    healthcheck:
      test: ["CMD", "pgrep", "-f", "python"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s

  # MCP Server - Model Context Protocol для поиска документов
  mcp-server:
    build:
      context: ..
      dockerfile: services/mcp_server/Dockerfile
    image: alpaca-mcp-server:latest
    restart: always
    networks:
      - alpaca_network
    ports:
      - "8083:8000"
    environment:
      # === CREDENTIALS ===
      - DATABASE_URL=${DATABASE_URL}
      
      # === SYSTEM SETTINGS ===
      - TZ=Europe/Moscow
      - LOG_LEVEL=INFO
      
      # === SERVICE URLs ===
      - OLLAMA_BASE_URL=${OLLAMA_BASE_URL:-http://host.docker.internal:11434}
      
      # === MODEL SETTINGS ===
      - OLLAMA_EMBEDDING_MODEL=bge-m3
      
      # === RAG SETTINGS ===
      - RAG_TOP_K=5
      - RAG_SIMILARITY_THRESHOLD=0.3
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s

  # Chat Backend - REST API для чата с RAG
  chat-backend:
    build:
      context: ..
      dockerfile: services/chat_backend/Dockerfile
    image: alpaca-chat-backend:latest
    restart: always
    networks:
      - alpaca_network
    ports:
      - "8082:8000"
    volumes:
      - ${MONITORED_FOLDER_PATH:-../monitored_folder}:/monitored_folder:ro  # Для скачивания документов
    environment:
      # === CREDENTIALS ===
      - DATABASE_URL=${DATABASE_URL}
      
      # === SYSTEM SETTINGS ===
      - TZ=Europe/Moscow
      - LOG_LEVEL=INFO
      - ENVIRONMENT=production
      - ROOT_PATH=/chat
      - PUBLIC_URL=https://api.alpaca-smart.com:8443/chat
      - APP_NAME=ALPACA Chat Backend
      - VERSION=1.0.0
      
      # === SERVICE URLs ===
      - OLLAMA_BASE_URL=${OLLAMA_BASE_URL:-http://host.docker.internal:11434}
      
      # === MODEL SETTINGS ===
      - OLLAMA_EMBEDDING_MODEL=bge-m3
      - OLLAMA_LLM_MODEL=qwen2.5:32b
      
      # === RAG SETTINGS ===
      - RAG_TOP_K=5
      - RAG_SIMILARITY_THRESHOLD=0.3
      - PIPELINE_TYPE=simple
      
      # === LLM BACKEND ===
      # CHAT_BACKEND: simple (RAG+Ollama) | agent (LangChain+MCP)
      - CHAT_BACKEND=agent
      - MCP_SERVER_URL=http://mcp-server:8000
      
      # Deprecated (use CHAT_BACKEND instead)
      - LLM_BACKEND=ollama
      
      # === STREAMING SETTINGS ===
      - STREAM_CHUNK_DELAY=0.02  # Задержка между чанками в секундах (0 = без задержки)
      
      # === FILE SETTINGS ===
      - MONITORED_PATH=/monitored_folder
    depends_on:
      - mcp-server
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s

volumes:
  unstructured_data:

networks:
  alpaca_network:
    driver: bridge

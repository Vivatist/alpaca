import os
import requests
from pydantic import BaseModel


class FileID(BaseModel):
    """–ò–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä —Ñ–∞–π–ª–∞ (hash + path)"""
    hash: str
    path: str


# –ò–º–ø–æ—Ä—Ç—ã –∏–∑ –ø—Ä–æ–µ–∫—Ç–∞ (–±—É–¥—É—Ç –¥–æ—Å—Ç—É–ø–Ω—ã –ø—Ä–∏ –∑–∞–ø—É—Å–∫–µ –∏–∑ main.py)
from settings import settings
from utils.database import Database
from utils.logging import get_logger

logger = get_logger("alpaca.parser")
db = Database(settings.DATABASE_URL)


def parser_word_old_task(file_id: dict) -> str:
    """–ü–∞—Ä—Å–∏–Ω–≥ DOCX —Ñ–∞–π–ª–∞ —á–µ—Ä–µ–∑ old parser (python-docx + OCR)"""
    file_id = FileID(**file_id)
    logger.info(f"üçÜ Processing parsing with old parser: {file_id.path}")
    
    from .word_parser_module.word_parser import WordParser
    try:
        word_parser = WordParser(enable_ocr=True, ocr_strategy='auto')
        full_path = os.path.join(settings.MONITORED_PATH, file_id.path)
        parse_result_dict = word_parser.parse(full_path)
        parse_result = parse_result_dict.get('markdown', '')
        
    except Exception as e:
        logger.error(f"Failed to parse file | file={file_id.path} error={type(e).__name__}: {e}")
        db.mark_as_error(file_id.hash)
        return ""
    logger.info(f"‚úÖ Parsed successfully | file={file_id.path} length={len(parse_result)}")
    return parse_result


def parser_word_task(file_id: dict) -> str:
    """–ü–∞—Ä—Å–∏–Ω–≥ –¥–æ–∫—É–º–µ–Ω—Ç–∞ —á–µ—Ä–µ–∑ Unstructured API"""
    file_id = FileID(**file_id)
    
    try:
        logger.info(f"üìñ Processing parsing: {file_id.path}")
        
        # –û—Ç–ø—Ä–∞–≤–∫–∞ —Ñ–∞–π–ª–∞ –≤ Unstructured API
        full_path = os.path.join(settings.MONITORED_PATH, file_id.path)
        
        full_path = os.path.join(settings.MONITORED_PATH, file_id.path)
        
        if not os.path.exists(full_path):
            logger.error(f"File not found: {full_path}")
            db.mark_as_error(file_id.hash)
            return ""
        
        with open(full_path, 'rb') as f:
            files = {'files': (file_id.path, f)}
            data = {
                'strategy': 'hi_res',  # hi_res –¥–ª—è OCR, auto –¥–ª—è –æ–±—ã—á–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
                'languages': 'rus,eng',
                'extract_image_block_types': '["Image", "Table"]',
                'coordinates': 'false',
            }
            
            logger.debug(f"Sending to Unstructured API | url={settings.UNSTRUCTURED_API_URL}")
            response = requests.post(
                settings.UNSTRUCTURED_API_URL,
                files=files,
                data=data,
                timeout=300  # 5 –º–∏–Ω—É—Ç –Ω–∞ –ø–∞—Ä—Å–∏–Ω–≥
            )
        
        if response.status_code != 200:
            logger.error(f"Unstructured API error | status={response.status_code} response={response.text[:200]}")
            db.mark_as_error(file_id.hash)
            return ""
        
        # –ü–∞—Ä—Å–∏–º –æ—Ç–≤–µ—Ç
        elements = response.json()
        
        if not elements:
            logger.warning(f"No elements returned from Unstructured | file={file_id.path}")
            return ""
        
        # –°–æ–±–∏—Ä–∞–µ–º —Ç–µ–∫—Å—Ç –∏–∑ —ç–ª–µ–º–µ–Ω—Ç–æ–≤ —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—ã
        markdown_parts = []
        
        for element in elements:
            if 'text' not in element or not element['text'].strip():
                continue
            
            text = element['text'].strip()
            element_type = element.get('type', 'NarrativeText')
            
            # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –ø–æ —Ç–∏–ø—É —ç–ª–µ–º–µ–Ω—Ç–∞
            if element_type == 'Title':
                markdown_parts.append(f"# {text}")
            elif element_type == 'Header':
                markdown_parts.append(f"## {text}")
            elif element_type == 'ListItem':
                markdown_parts.append(f"- {text}")
            elif element_type == 'Table':
                markdown_parts.append(f"\n{text}\n")
            elif element_type in ['NarrativeText', 'UncategorizedText', 'Text']:
                markdown_parts.append(text)
            elif element_type == 'Address':
                markdown_parts.append(f"**{text}**")
            elif element_type == 'EmailAddress':
                markdown_parts.append(f"`{text}`")
            else:
                # –ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ç–∏–ø - –ø—Ä–æ—Å—Ç–æ —Ç–µ–∫—Å—Ç
                markdown_parts.append(text)
        
        parsed_text = '\n\n'.join(markdown_parts)
        
        logger.info(f"‚úÖ Parsed successfully | file={file_id.path} elements={len(elements)} length={len(parsed_text)}")
        
        return parsed_text
        
    except requests.exceptions.Timeout:
        logger.error(f"Unstructured API timeout | file={file_id.path}")
        db.mark_as_error(file_id.hash)
        return ""
    except Exception as e:
        logger.error(f"Failed to parse file | file={file_id.path} error={type(e).__name__}: {e}")
        db.mark_as_error(file_id.hash)
        return ""



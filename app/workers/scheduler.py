"""
Scheduler –¥–ª—è –ø–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∏—Ö –∑–∞–¥–∞—á —Å Prefect
"""

import asyncio
import logging
from datetime import timedelta

from prefect import flow, task, serve

from settings import settings
from app.core.file_watcher import FileScanner
from app.db.connection import get_db
from app.workers.file_processor import process_queue_flow

logger = logging.getLogger(__name__)


@task(
    name="Scan Files",
    description="–°–∫–∞–Ω–∏—Ä—É–µ—Ç —Ñ–∞–π–ª–æ–≤—É—é —Å–∏—Å—Ç–µ–º—É –∏ –æ–±–Ω–æ–≤–ª—è–µ—Ç file_state"
)
async def scan_files_task() -> dict:
    """
    –°–∫–∞–Ω–∏—Ä—É–µ—Ç monitored_path –∏ —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∏—Ä—É–µ—Ç —Å –ë–î
    
    Returns:
        –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è
    """
    logger.info(f"üîç Scanning {settings.MONITORED_PATH}")
    
    scanner = FileScanner()
    disk_files = scanner.scan()
    
    logger.info(f"Found {len(disk_files)} files on disk")
    
    # –°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è —Å –ë–î
    stats = await sync_files_with_db(disk_files)
    
    logger.info(
        f"Sync stats: {stats['added']} added, {stats['updated']} updated, "
        f"{stats['unchanged']} unchanged, {stats['deleted']} deleted"
    )
    
    return stats


async def sync_files_with_db(disk_files: list) -> dict:
    """
    –°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∏—Ä—É–µ—Ç —Ñ–∞–π–ª—ã —Å –¥–∏—Å–∫–∞ —Å –ë–î (–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–æ –∏–∑ database.py)
    
    Args:
        disk_files: –°–ø–∏—Å–æ–∫ —Ñ–∞–π–ª–æ–≤ —Å –¥–∏—Å–∫–∞
    
    Returns:
        –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –æ–ø–µ—Ä–∞—Ü–∏–π
    """
    stats = {
        'added': 0,
        'updated': 0,
        'unchanged': 0,
        'deleted': 0
    }
    
    async with get_db() as db:
        # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ —Ö—ç—à–∏ –∏ –ø—É—Ç–∏ –∏–∑ –ë–î
        db_records = await db.fetch("SELECT file_hash, file_path FROM file_state")
        db_hashes = {row['file_hash']: row['file_path'] for row in db_records}
        db_paths = {row['file_path']: row['file_hash'] for row in db_records}
        
        # –°–æ–∑–¥–∞—ë–º –º–Ω–æ–∂–µ—Å—Ç–≤–∞ —Ö—ç—à–µ–π –∏ –ø—É—Ç–µ–π —Å –¥–∏—Å–∫–∞
        disk_hashes = {f['hash']: f for f in disk_files}
        disk_paths = {f['path'] for f in disk_files}
        
        # –ö–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä—É–µ–º —Ñ–∞–π–ª—ã
        for disk_hash, disk_file in disk_hashes.items():
            if disk_hash in db_hashes:
                # –•—ç—à —Å—É—â–µ—Å—Ç–≤—É–µ—Ç - —Ñ–∞–π–ª –Ω–µ –∏–∑–º–µ–Ω–∏–ª—Å—è
                stats['unchanged'] += 1
            else:
                # –ù–æ–≤—ã–π —Ö—ç—à - –ø—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ —Ñ–∞–π–ª —Å —Ç–∞–∫–∏–º –ø—É—Ç—ë–º –≤ –ë–î
                if disk_file['path'] in db_paths:
                    # –ü—É—Ç—å –µ—Å—Ç—å, –Ω–æ —Ö—ç—à –¥—Ä—É–≥–æ–π = —Ñ–∞–π–ª –∏–∑–º–µ–Ω–∏–ª—Å—è
                    stats['updated'] += 1
                else:
                    # –ù–∏ –ø—É—Ç–∏, –Ω–∏ —Ö—ç—à–∞ –Ω–µ—Ç = –Ω–æ–≤—ã–π —Ñ–∞–π–ª
                    stats['added'] += 1
        
        # –ë–∞—Ç—á–∏–Ω–≥ –≤—Å—Ç–∞–≤–∫–∏/–æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –¥–ª—è —Ñ–∞–π–ª–æ–≤ —Å –¥–∏—Å–∫–∞
        if disk_files:
            for disk_file in disk_files:
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º ON CONFLICT –¥–ª—è upsert
                await db.execute("""
                    INSERT INTO file_state (file_path, file_size, file_hash, file_mtime, last_checked, status_sync)
                    VALUES ($1, $2, $3, $4, NOW(), 'added')
                    ON CONFLICT (file_path) DO UPDATE SET
                        file_size = CASE 
                            WHEN file_state.status_sync = 'processed' THEN file_state.file_size
                            WHEN file_state.status_sync = 'error' THEN file_state.file_size
                            ELSE EXCLUDED.file_size
                        END,
                        file_hash = CASE 
                            WHEN file_state.status_sync = 'processed' THEN file_state.file_hash
                            WHEN file_state.status_sync = 'error' THEN file_state.file_hash
                            ELSE EXCLUDED.file_hash
                        END,
                        file_mtime = CASE 
                            WHEN file_state.status_sync = 'processed' THEN file_state.file_mtime
                            WHEN file_state.status_sync = 'error' THEN file_state.file_mtime
                            ELSE EXCLUDED.file_mtime
                        END,
                        last_checked = NOW(),
                        status_sync = CASE 
                            WHEN file_state.status_sync = 'error' THEN 'error'
                            WHEN file_state.status_sync = 'processed' THEN 'processed'
                            WHEN file_state.status_sync = 'deleted' THEN 'updated'
                            WHEN file_state.file_hash != EXCLUDED.file_hash THEN 'updated'
                            ELSE file_state.status_sync
                        END
                """, disk_file['path'], disk_file['size'], disk_file['hash'], disk_file['mtime'])
        
        # –ü–æ–º–µ—á–∞–µ–º —Ñ–∞–π–ª—ã, –∫–æ—Ç–æ—Ä—ã—Ö –Ω–µ—Ç –Ω–∞ –¥–∏—Å–∫–µ, –∫–∞–∫ deleted
        missing_paths = set(db_paths.keys()) - disk_paths
        if missing_paths:
            for path in missing_paths:
                result = await db.execute("""
                    UPDATE file_state 
                    SET status_sync = 'deleted', last_checked = NOW()
                    WHERE file_path = $1
                      AND status_sync NOT IN ('deleted', 'error')
                """, path)
            stats['deleted'] = len(missing_paths)
    
    return stats


@flow(
    name="File Watcher",
    description="–ü–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–æ–µ —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–æ–≤",
    log_prints=True
)
async def file_watcher_flow() -> dict:
    """
    –°–∫–∞–Ω–∏—Ä—É–µ—Ç —Ñ–∞–π–ª—ã –∏ –æ–±–Ω–æ–≤–ª—è–µ—Ç file_state
    
    Returns:
        –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è
    """
    return await scan_files_task()


@flow(
    name="Main Orchestrator",
    description="–ì–ª–∞–≤–Ω—ã–π –æ—Ä–∫–µ—Å—Ç—Ä–∞—Ç–æ—Ä: —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ + –æ–±—Ä–∞–±–æ—Ç–∫–∞",
    log_prints=True
)
async def main_orchestrator_flow():
    """
    –ì–ª–∞–≤–Ω—ã–π flow –∫–æ—Ç–æ—Ä—ã–π –∑–∞–ø—É—Å–∫–∞–µ—Ç –≤—Å–µ –∑–∞–¥–∞—á–∏
    
    1. –°–∫–∞–Ω–∏—Ä—É–µ—Ç —Ñ–∞–π–ª—ã (file_watcher)
    2. –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –æ—á–µ—Ä–µ–¥—å (process_queue)
    """
    logger.info("üéØ Starting main orchestrator")
    
    # 1. –°–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–æ–≤
    scan_stats = await file_watcher_flow()
    logger.info(f"Scan completed: {scan_stats}")
    
    # 2. –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—á–µ—Ä–µ–¥–∏
    process_stats = await process_queue_flow()
    logger.info(f"Processing completed: {process_stats}")
    
    return {
        'scan': scan_stats,
        'processing': process_stats
    }


async def serve_flows():
    """
    –ó–∞–ø—É—Å–∫–∞–µ—Ç Prefect flows —Å —Ä–∞—Å–ø–∏—Å–∞–Ω–∏–µ–º (Prefect 3.x API)
    """
    logger.info("üöÄ Starting Prefect flows...")
    
    # –ó–∞–ø—É—Å–∫ flows —Å —Ä–∞—Å–ø–∏—Å–∞–Ω–∏–µ–º —á–µ—Ä–µ–∑ serve()
    await serve(
        file_watcher_flow.to_deployment(
            name="file-watcher-periodic",
            interval=settings.SCAN_INTERVAL,
            tags=["file-watcher", "periodic"]
        ),
        main_orchestrator_flow.to_deployment(
            name="main-orchestrator",
            interval=60,  # –∫–∞–∂–¥—É—é –º–∏–Ω—É—Ç—É
            tags=["orchestrator", "main"]
        )
    )


async def run_once():
    """
    –ó–∞–ø—É—Å–∫–∞–µ—Ç –æ–¥–Ω—É –∏—Ç–µ—Ä–∞—Ü–∏—é main orchestrator (–¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è)
    """
    await main_orchestrator_flow()


if __name__ == "__main__":
    # –î–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è: –∑–∞–ø—É—Å–∫–∞–µ—Ç –æ–¥–Ω—É –∏—Ç–µ—Ä–∞—Ü–∏—é
    asyncio.run(run_once())

# üìÑ TXT Parser

## üéØ –ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ

TXT –ø–∞—Ä—Å–µ—Ä –æ—Ç–≤–µ—á–∞–µ—Ç –∑–∞ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –ø—Ä–æ—Å—Ç—ã—Ö —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö —Ñ–∞–π–ª–æ–≤ –≤ —Ñ–æ—Ä–º–∞—Ç Markdown —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏ YAML –¥–ª—è –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏ –≤ RAG —Å–∏—Å—Ç–µ–º–µ ALPACA.

**–ö–ª—é—á–µ–≤—ã–µ –æ—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏:**
- ‚úÖ **–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–æ–¥–∏—Ä–æ–≤–∫–∏** - –ø–æ–¥–¥–µ—Ä–∂–∫–∞ UTF-8, Windows-1251, CP866
- ‚úÖ **–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã** - –ø–∞—Ä–∞–≥—Ä–∞—Ñ—ã, –æ—Ç—Å—Ç—É–ø—ã, –ø—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏
- ‚úÖ **–ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ** - –∫–æ–¥–∏—Ä–æ–≤–∫–∞, –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–æ–∫/—Å–ª–æ–≤/—Å–∏–º–≤–æ–ª–æ–≤, –¥–∞—Ç—ã
- ‚úÖ **–ë—ã—Å—Ç—Ä–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞** - ~10ms –Ω–∞ —Ñ–∞–π–ª (–≤ 10000 —Ä–∞–∑ –±—ã—Å—Ç—Ä–µ–µ PDF —Å OCR)

---

## üèóÔ∏è –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞

### –ö–ª–∞—Å—Å `TXTParser`

```python
class TXTParser(BaseParser):
    """
    –ü–∞—Ä—Å–µ—Ä –¥–ª—è –ø—Ä–æ—Å—Ç—ã—Ö —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö —Ñ–∞–π–ª–æ–≤.
    
    Attributes:
        encoding_detector: chardet –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –∫–æ–¥–∏—Ä–æ–≤–∫–∏
        confidence_threshold: 0.7 - –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –ø–æ—Ä–æ–≥ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
    """
```

**–ù–∞—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ:** `BaseParser` (–≤–∞–ª–∏–¥–∞—Ü–∏—è, –æ–±—â–∏–µ —É—Ç–∏–ª–∏—Ç—ã)

**–ó–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏:**
- `chardet` - –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–æ–¥–∏—Ä–æ–≤–∫–∏ (UTF-8, Windows-1251, CP866, KOI8-R)
- `pathlib` - —Ä–∞–±–æ—Ç–∞ —Å –ø—É—Ç—è–º–∏ —Ñ–∞–π–ª–æ–≤
- `datetime` - –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –º–µ—Ç–∫–∏

---

## üìä 3-Stage Pipeline

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    TXT PARSER PIPELINE                      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

Input: plain text file ‚Üí Output: Markdown + YAML metadata

Stage 1: DETECT ENCODING
  ‚îú‚îÄ Read first 10KB
  ‚îú‚îÄ chardet.detect()
  ‚îú‚îÄ Check confidence > 70%
  ‚îî‚îÄ Fallback to UTF-8 if low confidence

Stage 2: READ & PARSE
  ‚îú‚îÄ Open file with detected encoding
  ‚îú‚îÄ Read all content
  ‚îú‚îÄ Extract metadata (lines, words, chars)
  ‚îî‚îÄ Get file stats (size, dates)

Stage 3: FORMAT MARKDOWN
  ‚îú‚îÄ Generate title from filename
  ‚îú‚îÄ Preserve paragraph structure
  ‚îú‚îÄ Create YAML frontmatter
  ‚îî‚îÄ Assemble final document
```

---

## üîç –î–µ—Ç–∞–ª–∏ —ç—Ç–∞–ø–æ–≤

### Stage 1: Detect Encoding

**–¶–µ–ª—å:** –û–ø—Ä–µ–¥–µ–ª–∏—Ç—å –∫–æ–¥–∏—Ä–æ–≤–∫—É —Ñ–∞–π–ª–∞ –¥–ª—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–≥–æ —á—Ç–µ–Ω–∏—è

**–ü—Ä–æ—Ü–µ—Å—Å:**
```python
def _detect_encoding(self, file_path: str) -> str:
    # 1. –ß–∏—Ç–∞–µ–º –ø–µ—Ä–≤—ã–µ 10KB (–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è)
    with open(file_path, 'rb') as f:
        raw_data = f.read(10240)
    
    # 2. –ò—Å–ø–æ–ª—å–∑—É–µ–º chardet
    detected = chardet.detect(raw_data)
    encoding = detected.get('encoding', 'utf-8')
    confidence = detected.get('confidence', 0.0)
    
    # 3. –ü—Ä–æ–≤–µ—Ä—è–µ–º —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å
    if confidence < 0.7:
        logger.warning(f"Low encoding confidence | detected={encoding} "
                      f"confidence={confidence:.2f} file={file_path}")
        return 'utf-8'  # –ë–µ–∑–æ–ø–∞—Å–Ω—ã–π fallback
    
    return encoding
```

**–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ –∫–æ–¥–∏—Ä–æ–≤–∫–∏:**
- UTF-8 (Unicode, —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–π —Å—Ç–∞–Ω–¥–∞—Ä—Ç)
- Windows-1251 (–∫–∏—Ä–∏–ª–ª–∏—Ü–∞, legacy —Å–∏—Å—Ç–µ–º—ã)
- CP866 (DOS –∫–∏—Ä–∏–ª–ª–∏—Ü–∞)
- KOI8-R (—Å—Ç–∞—Ä–∞—è Unix –∫–∏—Ä–∏–ª–ª–∏—Ü–∞)
- ASCII (–∞–Ω–≥–ª–∏–π—Å–∫–∏–π —Ç–µ–∫—Å—Ç)

**–õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ:**
```
[INFO] Detected encoding | encoding=utf-8
[WARNING] Low encoding confidence | detected=cp1251 confidence=0.45 file=...
```

**–ö—Ä–∏—Ç–µ—Ä–∏–∏ –≤—ã–±–æ—Ä–∞:**
- **–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å >= 70%** - –∏—Å–ø–æ–ª—å–∑—É–µ–º –æ–ø—Ä–µ–¥–µ–ª—ë–Ω–Ω—É—é –∫–æ–¥–∏—Ä–æ–≤–∫—É
- **–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å < 70%** - fallback –Ω–∞ UTF-8 (—Å–∞–º—ã–π —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π)

---

### Stage 2: Read & Parse Content

**–¶–µ–ª—å:** –ü—Ä–æ—á–∏—Ç–∞—Ç—å —Ñ–∞–π–ª –∏ –∏–∑–≤–ª–µ—á—å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ

**–ü—Ä–æ—Ü–µ—Å—Å:**
```python
def _extract_metadata(self, file_path: str, content: str) -> Dict[str, Any]:
    path = Path(file_path)
    stat = path.stat()
    
    # –ü–æ–¥—Å—á—ë—Ç –º–µ—Ç—Ä–∏–∫
    lines = content.count('\n') + 1
    words = len(content.split())
    characters = len(content)
    
    # –ü–æ–ª—É—á–µ–Ω–∏–µ –¥–∞—Ç
    created_time = datetime.fromtimestamp(stat.st_ctime)
    modified_time = datetime.fromtimestamp(stat.st_mtime)
    
    return {
        'title': path.stem,
        'encoding': detected_encoding,
        'lines': lines,
        'words': words,
        'characters': characters,
        'size_bytes': stat.st_size,
        'created': created_time.isoformat(),
        'modified': modified_time.isoformat()
    }
```

**–ò–∑–≤–ª–µ–∫–∞–µ–º—ã–µ –¥–∞–Ω–Ω—ã–µ:**
- **–°—Ç—Ä—É–∫—Ç—É—Ä–∞:** –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–æ–∫, —Å–ª–æ–≤, —Å–∏–º–≤–æ–ª–æ–≤
- **–ö–æ–¥–∏—Ä–æ–≤–∫–∞:** –æ–ø—Ä–µ–¥–µ–ª—ë–Ω–Ω–∞—è –Ω–∞ Stage 1
- **–†–∞–∑–º–µ—Ä:** –±–∞–π—Ç—ã
- **–í—Ä–µ–º–µ–Ω–Ω—ã–µ –º–µ—Ç–∫–∏:** —Å–æ–∑–¥–∞–Ω–∏–µ, –∏–∑–º–µ–Ω–µ–Ω–∏–µ

**–ü—Ä–∏–º–µ—Ä –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö:**
```yaml
title: contract_2024
encoding: windows-1251
lines: 150
words: 1250
characters: 8450
size_bytes: 10240
created: '2024-01-15T09:30:00'
modified: '2024-02-20T14:45:00'
```

---

### Stage 3: Format as Markdown

**–¶–µ–ª—å:** –°–æ–∑–¥–∞—Ç—å Markdown —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—ã

**–ü—Ä–æ—Ü–µ—Å—Å:**
```python
def _format_as_markdown(self, content: str, metadata: Dict[str, Any]) -> str:
    # 1. –ó–∞–≥–æ–ª–æ–≤–æ–∫ –∏–∑ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞
    title = metadata.get('title', '–ë–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è')
    
    # 2. –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø–∞—Ä–∞–≥—Ä–∞—Ñ—ã (—Ä–∞–∑–¥–µ–ª—ë–Ω–Ω—ã–µ –ø—É—Å—Ç—ã–º–∏ —Å—Ç—Ä–æ–∫–∞–º–∏)
    markdown_content = f"# {title}\n\n{content}"
    
    return markdown_content
```

**–°–æ—Ö—Ä–∞–Ω—è–µ–º–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞:**
- –ü–∞—Ä–∞–≥—Ä–∞—Ñ—ã (–ø—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏ –º–µ–∂–¥—É –±–ª–æ–∫–∞–º–∏ —Ç–µ–∫—Å—Ç–∞)
- –û—Ç—Å—Ç—É–ø—ã (–ø—Ä–æ–±–µ–ª—ã –≤ –Ω–∞—á–∞–ª–µ —Å—Ç—Ä–æ–∫)
- –ü–µ—Ä–µ–Ω–æ—Å—ã —Å—Ç—Ä–æ–∫
- –°–ø–µ—Ü—Å–∏–º–≤–æ–ª—ã (–±–µ–∑ —ç–∫—Ä–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è)

**–ü—Ä–∏–º–µ—Ä –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è:**
```
INPUT (UTF-8):
–î–æ–≥–æ–≤–æ—Ä ‚Ññ123

–ù–∞—Å—Ç–æ—è—â–∏–π –¥–æ–≥–æ–≤–æ—Ä –∑–∞–∫–ª—é—á—ë–Ω –º–µ–∂–¥—É:
- –û–û–û "–ö–æ–º–ø–∞–Ω–∏—è –ê"
- –û–û–û "–ö–æ–º–ø–∞–Ω–∏—è –ë"

–ü—Ä–µ–¥–º–µ—Ç –¥–æ–≥–æ–≤–æ—Ä–∞:
–ü–æ—Å—Ç–∞–≤–∫–∞ –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏—è.

OUTPUT (Markdown):
# contract_123

–î–æ–≥–æ–≤–æ—Ä ‚Ññ123

–ù–∞—Å—Ç–æ—è—â–∏–π –¥–æ–≥–æ–≤–æ—Ä –∑–∞–∫–ª—é—á—ë–Ω –º–µ–∂–¥—É:
- –û–û–û "–ö–æ–º–ø–∞–Ω–∏—è –ê"
- –û–û–û "–ö–æ–º–ø–∞–Ω–∏—è –ë"

–ü—Ä–µ–¥–º–µ—Ç –¥–æ–≥–æ–≤–æ—Ä–∞:
–ü–æ—Å—Ç–∞–≤–∫–∞ –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏—è.
```

---

## üìù YAML Frontmatter

**–§–æ—Ä–º–∞—Ç:**
```yaml
---
document_type: txt
file_name: contract.txt
file_path: /app/data/volume_documents/contract.txt
parsed_date: 2025-10-28T10:30:45.123456Z
parser: alpaca-txt-parser
title: contract
encoding: windows-1251
lines: 150
characters: 8450
words: 1250
size_bytes: 10240
created: '2024-01-15T09:30:00'
modified: '2024-02-20T14:45:00'
---
```

**–ü–æ–ª—è:**
- `document_type`: txt (–∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä —Ç–∏–ø–∞)
- `file_name`: –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–µ –∏–º—è —Ñ–∞–π–ª–∞
- `file_path`: –∞–±—Å–æ–ª—é—Ç–Ω—ã–π –ø—É—Ç—å –≤ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–µ
- `parsed_date`: –∫–æ–≥–¥–∞ –ø–∞—Ä—Å–∏–Ω–≥ –∑–∞–≤–µ—Ä—à—ë–Ω (ISO 8601)
- `parser`: alpaca-txt-parser (–≤–µ—Ä—Å–∏–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ)
- `title`: –∏–º—è —Ñ–∞–π–ª–∞ –±–µ–∑ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è
- `encoding`: –æ–ø—Ä–µ–¥–µ–ª—ë–Ω–Ω–∞—è –∫–æ–¥–∏—Ä–æ–≤–∫–∞ (–∫—Ä–∏—Ç–∏—á–Ω–æ –¥–ª—è RAG)
- `lines`, `words`, `characters`: –º–µ—Ç—Ä–∏–∫–∏ –∫–æ–Ω—Ç–µ–Ω—Ç–∞
- `size_bytes`: —Ä–∞–∑–º–µ—Ä –∏—Å—Ö–æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞
- `created`, `modified`: –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –º–µ—Ç–∫–∏ —Ñ–∞–π–ª–∞

**–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –≤ RAG:**
```python
# –ü—Ä–∏–º–µ—Ä –ø–æ–∏—Å–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –≤ –æ–ø—Ä–µ–¥–µ–ª—ë–Ω–Ω–æ–π –∫–æ–¥–∏—Ä–æ–≤–∫–µ
query = "encoding: windows-1251"

# –ü—Ä–∏–º–µ—Ä —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –ø–æ —Ä–∞–∑–º–µ—Ä—É
query = "size_bytes: >100000"  # –§–∞–π–ª—ã > 100KB
```

---

## üîß –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å Celery Task

**–§–∞–π–ª:** `tasks/txt_tasks.py`

```python
from parsers.txt.txt_parser import TXTParser
from parsers.markdown_writer import get_markdown_writer

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è (singleton)
txt_parser = TXTParser()
markdown_writer = get_markdown_writer('/volume_md')

@app.task(bind=True, name='tasks.txt_tasks.process_txt_file')
def process_txt_file(self, file_path: str, file_name: str, event: str):
    # 1. –ü–∞—Ä—Å–∏–Ω–≥ (3-stage pipeline)
    parse_result = txt_parser.parse(str(path))
    
    # 2. –í–∞–ª–∏–¥–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
    if parse_result.get('status') != 'success':
        raise ValueError(f"Parsing failed: {parse_result.get('error')}")
    
    # 3. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —á–µ—Ä–µ–∑ MarkdownWriter
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S_%f")[:-3]
    save_result = markdown_writer.save(
        parse_result=parse_result,
        file_name=file_name,
        timestamp=timestamp
    )
    
    # 4. –í–æ–∑–≤—Ä–∞—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
    return {
        'status': 'success',
        'file_path': file_path,
        'markdown_file': save_result['file_name'],
        'markdown_path': save_result['file_path'],
        'processing_time_sec': duration,
        'metadata': parse_result['metadata']
    }
```

**–û—á–µ—Ä–µ–¥—å:** `celery` (–¥–µ—Ñ–æ–ª—Ç–Ω–∞—è)

**Retry policy:** 3 –ø–æ–ø—ã—Ç–∫–∏ —Å —ç–∫—Å–ø–æ–Ω–µ–Ω—Ü–∏–∞–ª—å–Ω—ã–º backoff

---

## ‚ö° –ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å

### –ë–µ–Ω—á–º–∞—Ä–∫

| –ú–µ—Ç—Ä–∏–∫–∞ | –ó–Ω–∞—á–µ–Ω–∏–µ | –ö–æ–Ω—Ç–µ–∫—Å—Ç |
|---------|----------|----------|
| **–°–∫–æ—Ä–æ—Å—Ç—å –ø–∞—Ä—Å–∏–Ω–≥–∞** | ~10ms | –§–∞–π–ª 10KB, UTF-8 |
| **–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–æ–¥–∏—Ä–æ–≤–∫–∏** | 2-3ms | –ü–µ—Ä–≤—ã–µ 10KB —Ñ–∞–π–ª–∞ |
| **–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ Markdown** | 1-2ms | –ß–µ—Ä–µ–∑ MarkdownWriter |
| **–û–±—â–µ–µ –≤—Ä–µ–º—è** | 15ms | –û—Ç —Ñ–∞–π–ª–∞ –¥–æ Markdown |

**–°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å –¥—Ä—É–≥–∏–º–∏ –ø–∞—Ä—Å–µ—Ä–∞–º–∏:**
- TXT: **15ms** (baseline)
- Word: **500ms** (–≤ 33 —Ä–∞–∑–∞ –º–µ–¥–ª–µ–Ω–Ω–µ–µ - markitdown)
- PDF –±–µ–∑ OCR: **1.5s** (–≤ 100 —Ä–∞–∑ –º–µ–¥–ª–µ–Ω–Ω–µ–µ - pypdf)
- PDF —Å OCR: **155s** (–≤ 10000 —Ä–∞–∑ –º–µ–¥–ª–µ–Ω–Ω–µ–µ - Tesseract)

### –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏

1. **–ß–∞—Å—Ç–∏—á–Ω–æ–µ —á—Ç–µ–Ω–∏–µ –¥–ª—è –∫–æ–¥–∏—Ä–æ–≤–∫–∏** - —Ç–æ–ª—å–∫–æ 10KB –≤–º–µ—Å—Ç–æ –≤—Å–µ–≥–æ —Ñ–∞–π–ª–∞
2. **–ë–µ–∑ –≤–Ω–µ—à–Ω–∏—Ö –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π** - –Ω–µ—Ç markitdown, OCR, image libraries
3. **Singleton MarkdownWriter** - –ø–µ—Ä–µ–∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –∏–Ω—Å—Ç–∞–Ω—Å–∞
4. **–ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞** - —Å–æ—Ö—Ä–∞–Ω—è–µ–º –∫–∞–∫ –µ—Å—Ç—å, –±–µ–∑ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–π

---

## üß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ

### Test Cases

```bash
# 1. UTF-8 —Å —Ä—É—Å—Å–∫–∏–º —Ç–µ–∫—Å—Ç–æ–º
echo -e "–¢–µ—Å—Ç–æ–≤—ã–π –¥–æ–∫—É–º–µ–Ω—Ç\n\n–ü–∞—Ä–∞–≥—Ä–∞—Ñ 1.\n\n–ü–∞—Ä–∞–≥—Ä–∞—Ñ 2." > test_utf8.txt

# 2. Windows-1251 (legacy)
# –°–æ–∑–¥–∞—Ç—å –≤ —Ä–µ–¥–∞–∫—Ç–æ—Ä–µ, —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å —Å –∫–æ–¥–∏—Ä–æ–≤–∫–æ–π Windows-1251

# 3. –ë–æ–ª—å—à–æ–π —Ñ–∞–π–ª (1MB+)
dd if=/dev/urandom of=test_large.txt bs=1M count=5

# 4. –§–∞–π–ª —Å emoji (UTF-8)
echo "üöÄ –ó–∞–ø—É—Å–∫ —Å–∏—Å—Ç–µ–º—ã üéØ –¶–µ–ª—å –¥–æ—Å—Ç–∏–≥–Ω—É—Ç–∞ ‚úÖ" > test_emoji.txt
```

### –û–∂–∏–¥–∞–µ–º—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã

**UTF-8:**
```
[INFO] Detected encoding | encoding=utf-8
[INFO] Metadata extracted | lines=5 chars=45
[INFO] TXT parsed successfully | content_length=50
```

**Windows-1251:**
```
[INFO] Detected encoding | encoding=windows-1251
[INFO] Metadata extracted | lines=100 chars=5000
[INFO] TXT parsed successfully | content_length=5050
```

**–ù–∏–∑–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å:**
```
[WARNING] Low encoding confidence | detected=iso-8859-1 confidence=0.45
[INFO] Using fallback encoding | encoding=utf-8
```

---

## üö® Error Handling

### –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º—ã–µ —Å–∏—Ç—É–∞—Ü–∏–∏

1. **–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω:**
```python
if not path.exists():
    return {'status': 'error', 'error': 'File not found'}
```

2. **–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è:**
```python
except UnicodeDecodeError as e:
    logger.error(f"Encoding error | file={file_path} encoding={encoding}")
    # Retry —Å UTF-8
```

3. **–ù–µ–æ–ø—Ä–µ–¥–µ–ª—ë–Ω–Ω–∞—è –∫–æ–¥–∏—Ä–æ–≤–∫–∞:**
```python
if detected.get('encoding') is None:
    logger.warning(f"Could not detect encoding | file={file_path}")
    encoding = 'utf-8'  # Fallback
```

4. **–ü—É—Å—Ç–æ–π —Ñ–∞–π–ª:**
```python
if len(content.strip()) == 0:
    logger.warning(f"Empty file | file={file_path}")
    # –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º –ø–∞—Ä—Å–∏–Ω–≥, —Å–æ—Ö—Ä–∞–Ω—è–µ–º –ø—É—Å—Ç–æ–π Markdown
```

### –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—à–∏–±–æ–∫

```
[ERROR] File processing error | file=contract.txt error=UnicodeDecodeError: 'utf-8' codec can't decode
[WARNING] Retrying with fallback encoding | file=contract.txt encoding=windows-1251
[INFO] Successfully parsed on retry | file=contract.txt encoding=windows-1251
```

---

## üîó –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å MarkdownWriter

**–£–Ω–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø–∞—Ç—Ç–µ—Ä–Ω:**

```python
# TXT Parser –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç
parse_result = {
    'status': 'success',
    'content': markdown_text,  # –£–∂–µ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π Markdown
    'metadata': {
        'title': 'contract',
        'encoding': 'windows-1251',
        'lines': 150,
        # ... –æ—Å—Ç–∞–ª—å–Ω—ã–µ –ø–æ–ª—è
    }
}

# MarkdownWriter —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç
save_result = markdown_writer.save(
    parse_result=parse_result,
    file_name='contract.txt',
    timestamp='20251028_103045_123'
)

# –†–µ–∑—É–ª—å—Ç–∞—Ç:
# /volume_md/20251028_103045_123_contract.md
```

**–ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞:**
- –ï–¥–∏–Ω—ã–π –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å –¥–ª—è –≤—Å–µ—Ö –ø–∞—Ä—Å–µ—Ä–æ–≤ (PDF, Word, TXT)
- –¶–µ–Ω—Ç—Ä–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–∞—è –ª–æ–≥–∏–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–º—ë–Ω —Ñ–∞–π–ª–æ–≤
- –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è —Ç—Ä–∞–Ω—Å–ª–∏—Ç–µ—Ä–∞—Ü–∏—è –∫–∏—Ä–∏–ª–ª–∏—Ü—ã
- –ö–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω—ã–µ YAML –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ

---

## üì¶ –ó–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏

**requirements.txt:**
```txt
chardet==5.2.0  # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–æ–¥–∏—Ä–æ–≤–∫–∏
```

**–£—Å—Ç–∞–Ω–æ–≤–∫–∞:**
```bash
pip install -r requirements.txt
```

**Docker:**
```dockerfile
# –£–∂–µ –≤–∫–ª—é—á–µ–Ω–æ –≤ –±–∞–∑–æ–≤—ã–π –æ–±—Ä–∞–∑
COPY document-processors/requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt
```

---

## üéì Use Cases

### 1. Legacy –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è

**–ü—Ä–æ–±–ª–µ–º–∞:** –°—Ç–∞—Ä—ã–µ –¥–æ–≥–æ–≤–æ—Ä—ã –≤ Windows-1251

**–†–µ—à–µ–Ω–∏–µ:**
```python
# –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–æ–¥–∏—Ä–æ–≤–∫–∏
parse_result = txt_parser.parse('legacy_contract.txt')
# encoding=windows-1251 –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ–±–Ω–∞—Ä—É–∂–µ–Ω
```

### 2. –≠–∫—Å–ø–æ—Ä—Ç –∏–∑ CRM

**–ü—Ä–æ–±–ª–µ–º–∞:** CSV —ç–∫—Å–ø–æ—Ä—Ç—ã —Å —Ç–∞–±—É–ª—è—Ü–∏–µ–π

**–†–µ—à–µ–Ω–∏–µ:**
```python
# TXT –ø–∞—Ä—Å–µ—Ä —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä—É
# –¢–∞–±—É–ª—è—Ü–∏—è –∏ –æ—Ç—Å—Ç—É–ø—ã –æ—Å—Ç–∞—é—Ç—Å—è –∫–∞–∫ –µ—Å—Ç—å
```

### 3. Email –ø–µ—Ä–µ–ø–∏—Å–∫–∞

**–ü—Ä–æ–±–ª–µ–º–∞:** .eml —Ñ–∞–π–ª—ã —ç–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω—ã –≤ .txt

**–†–µ—à–µ–Ω–∏–µ:**
```python
# –ü–∞—Ä—Å–∏–º –∫–∞–∫ –æ–±—ã—á–Ω—ã–π —Ç–µ–∫—Å—Ç
# –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –≤–∫–ª—é—á–∞—é—Ç –¥–∞—Ç—É —Å–æ–∑–¥–∞–Ω–∏—è/–∏–∑–º–µ–Ω–µ–Ω–∏—è
```

### 4. –õ–æ–≥–∏ —Å–∏—Å—Ç–µ–º

**–ü—Ä–æ–±–ª–µ–º–∞:** –ù—É–∂–Ω–æ –∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞—Ç—å –ª–æ–≥–∏ –¥–ª—è –ø–æ–∏—Å–∫–∞

**–†–µ—à–µ–Ω–∏–µ:**
```python
# TXT –ø–∞—Ä—Å–µ—Ä –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –º–Ω–æ–≥–æ—Å—Ç—Ä–æ—á–Ω—ã–µ –ª–æ–≥–∏
# –°–æ—Ö—Ä–∞–Ω—è–µ—Ç –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –º–µ—Ç–∫–∏ –≤ metadata
```

---

## üîÑ –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∏ –º–∏–≥—Ä–∞—Ü–∏—è

### –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –Ω–æ–≤–æ–π –∫–æ–¥–∏—Ä–æ–≤–∫–∏

```python
# –í _detect_encoding() –¥–æ–±–∞–≤–∏—Ç—å fallback:
ENCODING_FALLBACKS = {
    'iso-8859-1': 'windows-1251',  # Latin-1 ‚Üí CP1251
    'ascii': 'utf-8',               # ASCII ‚Üí UTF-8
}

detected_encoding = chardet.detect(raw_data)['encoding']
encoding = ENCODING_FALLBACKS.get(detected_encoding, detected_encoding)
```

### –ú–∏–≥—Ä–∞—Ü–∏—è —Å—Ç–∞—Ä—ã—Ö —Ñ–∞–π–ª–æ–≤

```bash
# –ü–µ—Ä–µ–∏–Ω–¥–µ–∫—Å–∞—Ü–∏—è –≤—Å–µ—Ö TXT —Ñ–∞–π–ª–æ–≤
find /volume_documents -name "*.txt" -type f | while read file; do
    # Trigger Celery task
    celery call tasks.txt_tasks.process_txt_file \
        --args="['$file', '$(basename $file)', 'reindex']"
done
```

---

## üìö –°–º. —Ç–∞–∫–∂–µ

- **MARKDOWN_WRITER.md** - –¶–µ–Ω—Ç—Ä–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–π –º–æ–¥—É–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
- **COMPARISON.md** - –°—Ä–∞–≤–Ω–µ–Ω–∏–µ TXT vs PDF vs Word –ø–∞—Ä—Å–µ—Ä–æ–≤
- **word/README.md** - Word –ø–∞—Ä—Å–µ—Ä (7 stages)
- **pdf/README.md** - PDF –ø–∞—Ä—Å–µ—Ä (5 stages + OCR)

---

## üìû –ö–æ–Ω—Ç–∞–∫—Ç—ã

**–ü—Ä–æ–µ–∫—Ç:** ALPACA Document Processing  
**–í–µ—Ä—Å–∏—è:** 1.0.0  
**–ü–∞—Ä—Å–µ—Ä:** alpaca-txt-parser  
**–õ–∏—Ü–µ–Ω–∑–∏—è:** Proprietary (–û–û–û "–ì–µ–æ—Ä–µ–∑–æ–Ω–∞–Ω—Å")
